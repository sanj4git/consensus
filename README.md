# CONSENSUS

# ğŸ§  Learning-Aware Generative AI System  
### Adversarial Multi-Agent LLM Council for Education

---

## ğŸ“Œ Overview

Generative AI systems are fast and fluent, but **not learning-aware**.  
In educational contexts, this leads to **hallucinations**, **off-curriculum explanations**, and **level-inappropriate content**, creating a heavy verification burden for teachers, students, and institutions.

This project presents a **Learning-Aware Generative AI System** that replaces single-model generation with a **multi-agent academic council**.  
Instead of trusting one AI output, content is **generated, verified, stress-tested, revised, and approved** before being shown to the user.

---

## ğŸš¨ Problem Statement

In real classrooms and self-learning platforms:

- AI generates confident but **factually incorrect explanations**
- Content **drifts away from prescribed curricula**
- Explanations are **misaligned with student learning levels**
- Educators face a growing **verification bottleneck**

Existing LLMs optimize for fluency, not for **correctness, curriculum alignment, or pedagogy**.

---

## ğŸ’¡ Proposed Solution: LLM Council Architecture

<img width="419" height="165" alt="image" src="https://github.com/user-attachments/assets/5f7c4a14-9023-4333-b67a-a9e79645555b" />

We introduce an **Adversarial Multi-Agent System** inspired by academic peer review.

Instead of a single AI monologue, content passes through a **Council of Specialized LLM Agents**, each responsible for enforcing a specific educational constraint.

Only **Council-approved content** reaches the user.

---

## ğŸ›ï¸ LLM Council Roles

| Agent | Responsibility |
|-----|---------------|
| **Content Architect** | Generates an initial syllabus-grounded draft |
| **Curriculum Watchdog** | Verifies strict curriculum alignment |
| **Fact Sentinel** | Detects unsupported or hallucinated claims |
| **Simulated Student** | Tests clarity and level-appropriateness |
| **Chairman** | Aggregates verdicts, enforces revision, approves output |

---

## ğŸ” System Flow

User Question
â†“
Curriculum Retrieval (RAG)
â†“
Content Architect (Draft)
â†“
Curriculum Watchdog (Scope Check)
â†“
Fact Sentinel (Factual Check)
â†“
Simulated Student (Level Check)
â†“
Chairman (Decision + Rewrite)
â†“
Final Answer + Review Trace


This pipeline **mechanically reduces hallucinations** and enforces pedagogical correctness.

---

## ğŸ§± Architecture Diagram

<img width="1155" height="432" alt="image" src="https://github.com/user-attachments/assets/7a977cbb-ddc3-4db3-87d2-911ae81c104e" />



---

## âœ¨ Key Features

- ğŸ“š Curriculum-aware content generation  
- ğŸ§  Hallucination prevention via independent verification  
- ğŸ“ Level-appropriate explanations  
- ğŸ” Explainable AI with review trace  
- ğŸ’¬ Persistent project-based chat history  
- ğŸ—‚ï¸ PDF syllabus upload & semantic retrieval  
- ğŸ” Multi-user authentication and project isolation  

---

## ğŸ› ï¸ Tech Stack

### Frontend
- React
- shadcn/ui
- Tailwind CSS

### Backend
- Node.js + Express
- MongoDB

### AI & ML
- Google Gemini (LLM Agents)
- Sentence Transformers (Embeddings)
- Python FastAPI (Embedding Service)
- Retrieval-Augmented Generation (RAG)

---

## ğŸ¯ Why This Matters

AI in education must be **governed, not just prompted**.

By enforcing **structured disagreement and consensus**, this system transforms generative AI from a risky shortcut into a **reliable, curriculum-aligned, and pedagogically sound teaching assistant**.

---

## ğŸ Future Scope

- Persistent review trace storage
- Teacher-controlled agent configuration
- Bias and inclusivity checks
- Presentation generation
- Voice-based interaction

---

## ğŸŒ± Inspiration

This work is inspired by **Andrej Karpathyâ€™s idea of â€œLLM Councilsâ€**, where multiple specialized models critique and refine each other instead of relying on a single monolithic generation.  

We adapt this concept to the **education domain**, emphasizing curriculum alignment, factual correctness, and learner-level appropriateness through adversarial yet cooperative agent roles.

---

---

## ğŸ‘¥ Team

Built during a **24-hour hackathon** by a team of two, focusing on **correctness, explainability, and educational impact**.

---
